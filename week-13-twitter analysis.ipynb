{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Make sure that you have installed the twitter library\n",
    "- pip install -i https://pypi.anaconda.org/pypi/simple twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='/home/drk/kanungo/DNSC6211/week13-twitter/PartB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "def getAuthData():\n",
    "    import csv\n",
    "    with open(path+'authdata.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        your_list = list(reader)\n",
    "\n",
    "    authdata = {}   \n",
    "    for element in your_list:\n",
    "        authdata[element[0]] = element[1]\n",
    "\n",
    "    return authdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getAuthData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwitterData(searchTerm):\n",
    "    \n",
    "    authdata = getAuthData()\n",
    "\n",
    "    CONSUMER_KEY = authdata['CONSUMER_KEY']\n",
    "    CONSUMER_SECRET = authdata['CONSUMER_SECRET']\n",
    "    OAUTH_TOKEN = authdata['OAUTH_TOKEN']\n",
    "    OAUTH_TOKEN_SECRET = authdata['OAUTH_TOKEN_SECRET']\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN,\n",
    "                               OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY,\n",
    "                               CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    \n",
    "    # Nothing to see by displaying twitter_api except that it's now a defined variable\n",
    "    print (twitter_api)\n",
    "    \n",
    "    searchCount = 1800 # The number of tweets you want ... you never get that !\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "    search_results = twitter_api.search.tweets(q=searchTerm, count=searchCount)\n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through 5 more batches of results by following the cursor\n",
    "    \n",
    "    for _ in range(5):\n",
    "        print (\"Length of statuses\", len(statuses))\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            print (\"That's all folks for ...\", searchTerm)\n",
    "            break\n",
    "        myKVs = [ kv.split('=') for kv in next_results[1:].split(\"&\") ]\n",
    "        myStrippedKVs = [ [str(pp[0]), str(pp[1])] for pp in myKVs]\n",
    "        kwargs = dict(myStrippedKVs)    \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "    \n",
    "    status_texts = [ status['text'] for status in statuses ]\n",
    "    return status_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is new ...\n",
    "# Get and save twitter data\n",
    "\n",
    "tweetTexts = getTwitterData('@Delta')\n",
    "with open(path+'tw_delta.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n",
    "tweetTexts = getTwitterData('@United')\n",
    "with open(path+'tw_united.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n",
    "tweetTexts = getTwitterData('@USAirways')\n",
    "with open(path+'tw_usair.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n",
    "tweetTexts = getTwitterData('@Southwest')\n",
    "with open(path+'tw_southwest.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n",
    "tweetTexts = getTwitterData('@American')\n",
    "with open(path+'tw_american.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n",
    "tweetTexts = getTwitterData('@JetBlue')\n",
    "with open(path+'tw_jetblue.txt','w') as f:\n",
    "    f.writelines(tweetTexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get negative and positive word lists\n",
    "def getWordLists():\n",
    "    negative = [line.strip() for line in open(path+'neg.txt')]\n",
    "    negative = [n for n in negative if n != [] ]\n",
    "    negative = [n for n in negative if n != '' ]\n",
    "    negative = [n for n in negative if n[0] != ';']\n",
    "    \n",
    "    positive = [line.strip() for line in open(path+'pos.txt')]\n",
    "    positive = [n for n in positive if n != [] ]\n",
    "    positive = [n for n in positive if n != '' ]\n",
    "    positive = [n for n in positive if n[0] != ';']\n",
    "\n",
    "    return negative, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative , positive= getWordLists()\n",
    "#print (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning + Sentiment scores\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    punctuation = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    s_sans_punct = \"\"\n",
    "    for letter in s:\n",
    "        if (letter not in punctuation) and (letter in \"abcdefghijklmnopqrstuvwxyz \"):\n",
    "            s_sans_punct += letter\n",
    "    return s_sans_punct\n",
    "\n",
    "def getLowerCaseText(status_texts):\n",
    "    lowered_texts = []\n",
    "    for texts in status_texts:\n",
    "        try: \n",
    "            mytext = str(texts.lower())\n",
    "            lowered_texts.append(mytext)\n",
    "        except:\n",
    "            pass\n",
    "    return lowered_texts\n",
    "\n",
    "def getCleanedTweets(lowered_texts):\n",
    "    cleanedTweets = []\n",
    "    for text in lowered_texts:\n",
    "        wordlist = str(text).split()\n",
    "        wordlist_nopun = [ str(remove_punctuation(for_a_word)) for for_a_word in wordlist ]\n",
    "        cleanedTweets.append(wordlist_nopun)\n",
    "    return cleanedTweets\n",
    "\n",
    "def GetSentimentScores(cleanedTweets, negative, positive):\n",
    "    freqList = []\n",
    "    for eachTweet in cleanedTweets:\n",
    "        posScore = len(set(eachTweet) & set(positive))\n",
    "        negScore = len(set(eachTweet) & set(negative))\n",
    "        freqList.append(posScore-negScore)\n",
    "    return freqList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting routines\n",
    "\n",
    "def plotHist(freqList):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(freqList)\n",
    "\n",
    "def getTwitterScore(freqList):\n",
    "    veryNegative = len([x for x in freqList if x<=-2])\n",
    "    veryPositive = len([x for x in freqList if x>=+2])\n",
    "    twitterScore = 100 * (float (veryPositive) / (veryNegative + veryPositive))\n",
    "    return round(twitterScore, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get airline data\n",
    "# This should work --- but is not working as of today \n",
    "# I have created an alternative function below - manual data entry ... ugh!!\n",
    "def getAirlineData():\n",
    "    from bs4 import BeautifulSoup as bs  \n",
    "    import requests\n",
    "    url = 'https://www.theacsi.org/?option=com_content&view=article&id=147&catid=14&Itemid=212&i=Airlines'\n",
    "    r = requests.get(url)\n",
    "    airlinesSatPage = r.text       \n",
    "    soup = bs(airlinesSatPage, \"html.parser\")\n",
    "\n",
    "    allRows = soup.findAll('tr',{'class':'Company'})\n",
    "    tableData = []\n",
    "    for row in allRows:\n",
    "        eachRow = []\n",
    "        cells = row.findAll('td')\n",
    "        for cell in cells:\n",
    "            eachRow.append(str(cell.text.strip()))\n",
    "        tableData.append(eachRow)\n",
    "\n",
    "    airline = [ x[0] for x in tableData ]\n",
    "    score   = [ x[21] for x in tableData ]\n",
    "    airlineDict = { 'airlines': airline,\n",
    "                    'score'   : score\n",
    "                  }\n",
    "    \n",
    "    return airlineDict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAirlineDataAlt():\n",
    "    airlineDict = {}\n",
    "    airlineDict = {'JetBlue':80, \n",
    "                   'Southwest':80,\n",
    "                   'American':72,\n",
    "                   'Delta':71,\n",
    "                   'United':68\n",
    "                  }\n",
    "    return airlineDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlineScores = getAirlineDataAlt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getScore(fileName):\n",
    "    fn = path+fileName+'.txt'\n",
    "    with open(fn,'r') as f:\n",
    "        tweetTexts = f.readlines()\n",
    "    lowered_texts = getLowerCaseText(tweetTexts)\n",
    "    cleanedTweets = getCleanedTweets(lowered_texts)\n",
    "    freqList = GetSentimentScores(cleanedTweets, negative, positive)\n",
    "    score = getTwitterScore(freqList)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "scores = {'American': getScore('tw_american'),\n",
    "          'Delta': getScore('tw_delta'),\n",
    "          'JetBlue':  getScore('tw_jetblue'),\n",
    "          'Southwest': getScore('tw_southwest'),\n",
    "          'United': getScore('tw_united'),\n",
    "          'USAirways': getScore('tw_usair')\n",
    "         }\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "twdf = pd.DataFrame.from_dict(scores, orient='index')\n",
    "twdf.columns = ['twitterScore']\n",
    "print(twdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "airdf = pd.DataFrame.from_dict(airlineScores, orient='index')\n",
    "airdf.columns = ['airlineScore']\n",
    "print(airdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set([\"a\",\"b\",\"c\"]) & set([\"a\",\"d\",\"c\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([twdf, airdf], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(result['twitterScore'], result['airlineScore'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
